{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "941b171b-cfd4-4d18-b846-0c0518e01b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import s3fs\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3747311a-f127-455e-ae64-139a64f432f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook aims to generate the WIT plots after we finish the WIT Airflow DAG (https://github.com/GeoscienceAustralia/dea-airflow/blob/develop/dags/k8s_wit_tooling_conflux.py) running\n",
    "# Assume we are using follow Airflow config to start Airflow DAG run\n",
    "airflow_run_cfg = {\n",
    "\"shapefile\": \"s3://dea-public-data-dev/projects/WIT/test_shp/Ramsar_WIT2_update_UID.shp\",\n",
    "\"intermediatedir\": \"s3://dea-public-data-dev/projects/WIT/Ramsar_WIT2_update_UID_result_pq\",\n",
    "\"csvdir\": \"s3://dea-public-data-dev/projects/WIT/Ramsar_WIT2_update_UID_result\",\n",
    "\"cmd\": \"'gqa_mean_x in [-1, 1]'\",\n",
    "\"flags\": \"\"\n",
    "}\n",
    "\n",
    "csvdir = airflow_run_cfg['csvdir']\n",
    "shapefile = airflow_run_cfg['shapefile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59c845ff-3c2f-4aea-a336-d61cf23bb2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(csv_file_path):\n",
    "    df = pd.read_csv(\"s3://\" + csv_file_path)\n",
    "    # add csv file path to debug\n",
    "    df[\"s3_csv_path\"] = csv_file_path\n",
    "    if df.empty is True:\n",
    "        return pd.DataFrame()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26520e9c-b2f3-4b48-87df-d679f14888f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269/269 [00:05<00:00, 50.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# Setup the AWS S3 access\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "# we need load the polygon file to access polygon human-readable information\n",
    "polygons = gpd.read_file(shapefile)\n",
    "\n",
    "# load the WIT result from Airflow DAG running output folder\n",
    "conflux_c3_csv_files = fs.find(csvdir)\n",
    "\n",
    "# ignore the debug.csv\n",
    "conflux_c3_csv_files = [e for e in conflux_c3_csv_files if 'debug' not in e]\n",
    "\n",
    "wit_dfs = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(load_csv)(\"s3://\" + e ) for e in tqdm(conflux_c3_csv_files))\n",
    "\n",
    "# make sure we clean data before display\n",
    "wit_dfs = [e[e['pc_missing'] < 0.1] for e in wit_dfs]\n",
    "wit_dfs = [e.dropna(subset=['bs']) for e in wit_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eba7641c-4c3b-4c9b-a293-1c94392ee30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_polygon_names(feature_id, polygons, df_size):\n",
    "    # full of hard-code values which belong to this shape file\n",
    "    # maybe just keep the simple version (feature_id.png) as PNG name in the future\n",
    "    try:\n",
    "        RAMSAR_NAM = polygons[polygons['UID'] == feature_id].iloc[0]['RAMSAR_NAM']\n",
    "        wetland_name = polygons[polygons['UID'] == feature_id].iloc[0]['WETLAND_NA']\n",
    "        png_name = f\"{str(feature_id).zfill(3)}-{RAMSAR_NAM}-{wetland_name}\"\n",
    "        plot_title = f\"{RAMSAR_NAM} {wetland_name} - ID {feature_id}: {df_size} scenes\"\n",
    "    except:\n",
    "        png_name = str(feature_id)\n",
    "        plot_title = f\"ID {feature_id}: {df_size} scenes in C3\"\n",
    "\n",
    "    return plot_title, png_name\n",
    "\n",
    "\n",
    "def display_wit_as_stack_plot(wit_df, polygons=None, png_folder_name=\"wit_png\", width=30, height=5):\n",
    "\n",
    "    # if we try to display an empty CSV, skip it\n",
    "    if len(wit_df) == 0:\n",
    "        return\n",
    "\n",
    "    feature_id = list(wit_df['feature_id'])[-1]\n",
    "\n",
    "    pal = ['#030AA7',\n",
    "           '#04D9FF',\n",
    "           '#3F9B0B',\n",
    "           '#E6DAA6',\n",
    "           '#60460F']\n",
    "\n",
    "    if len(wit_df) > 500:\n",
    "        upscale = int(len(wit_df) // 15)\n",
    "    else:\n",
    "        upscale = int(len(wit_df) // 20)\n",
    "\n",
    "    if upscale == 0:\n",
    "        upscale = 1\n",
    "\n",
    "    wit_df['display_time'] = [e.split(\"T\")[0] for e in wit_df['date']]\n",
    "\n",
    "    wit_xs = wit_df['display_time']\n",
    "    wit_ys = wit_df[[\"water\", \"wet\", \"pv\", \"npv\", \"bs\"]]\n",
    "    wit_ys = wit_ys.clip(0, 1)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(width, height)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.autoscale(enable=True)\n",
    "\n",
    "    plot_title, png_name = generate_polygon_names(feature_id, polygons, len(wit_df))\n",
    "\n",
    "    plt.title(plot_title, fontsize=16)\n",
    "\n",
    "    ax.stackplot(wit_xs, wit_ys[\"water\"], wit_ys[\"wet\"], wit_ys[\"pv\"], wit_ys[\"npv\"], wit_ys[\"bs\"], colors=pal, alpha=0.6)\n",
    "\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xlim(wit_xs.min(), wit_xs.max())\n",
    "\n",
    "    xlabels = []\n",
    "\n",
    "    for n,i in enumerate(wit_xs):\n",
    "        if n%upscale==0:\n",
    "            xlabels.append(i)\n",
    "        else:\n",
    "            xlabels.append('')\n",
    "\n",
    "    ax.set_xticks(xlabels)\n",
    "\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel(\"Fraction\")\n",
    "\n",
    "    wit_df.to_csv(f\"{png_folder_name}/{png_name}.csv\", index=False)\n",
    "    plt.savefig(f\"{png_folder_name}/{png_name}.png\")\n",
    "    #plt.show()\n",
    "\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2604666a-8d6b-465a-90da-fcd722c8adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "png_folder_name = \"wit_png\"\n",
    "\n",
    "Path(png_folder_name).mkdir(exist_ok=True)\n",
    "\n",
    "# Only display the first one to make it display well\n",
    "for wit_df in wit_dfs[:1]:\n",
    "    display_wit_as_stack_plot(wit_df, polygons, png_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c32ec6e-6026-447a-86f6-d4676434cae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_165/3295042569.py:56: UserWarning: Attempting to set identical left == right == [0.] results in singular transformations; automatically expanding.\n",
      "  ax.set_xlim(wit_xs.min(), wit_xs.max())\n"
     ]
    }
   ],
   "source": [
    "# Run all\n",
    "for wit_df in wit_dfs:\n",
    "    display_wit_as_stack_plot(wit_df, polygons, png_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e100aa05-2a10-43db-8bc7-aa377d45a001",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
